# ü§ñ SMIMSO AI Service

AI Service cho SMIMSO s·ª≠ d·ª•ng CLIP v√† BLIP models.

## üéØ T√≠nh NƒÉng

- ‚úÖ **CLIP Image Embedding** - T·∫°o vector embedding 512 chi·ªÅu cho ·∫£nh
- ‚úÖ **BLIP Image Captioning** - T·ª± ƒë·ªông t·∫°o m√¥ t·∫£ cho ·∫£nh
- ‚úÖ **Zero-shot Classification** - Ph√¢n lo·∫°i ·∫£nh kh√¥ng c·∫ßn training
- ‚úÖ **Text-to-Image Search** - T√¨m ki·∫øm ·∫£nh b·∫±ng text
- ‚úÖ **Image Similarity** - T√¨m ·∫£nh t∆∞∆°ng t·ª±

## üöÄ C√†i ƒê·∫∑t

### **Option 1: Ch·∫°y Tr·ª±c Ti·∫øp (Python)**

#### **1. T·∫°o Virtual Environment:**

```bash
cd AI_SERVICE
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

#### **2. C√†i Dependencies:**

```bash
pip install -r requirements.txt
```

**L∆∞u √Ω:** 
- C·∫ßn Python 3.8+
- PyTorch s·∫Ω t·ª± ƒë·ªông c√†i CPU version
- N·∫øu c√≥ GPU, c√†i PyTorch GPU version:
  ```bash
  pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
  ```

#### **3. Ch·∫°y Service:**

```bash
python main.py
```

ho·∫∑c

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

Service s·∫Ω ch·∫°y t·∫°i: **http://localhost:8000**

---

### **Option 2: Ch·∫°y B·∫±ng Docker**

#### **1. Build Image:**

```bash
cd AI_SERVICE
docker build -t smimso-ai-service .
```

#### **2. Run Container:**

```bash
docker run -p 8000:8000 smimso-ai-service
```

---

## üì° API Endpoints

### **1. Health Check**

```bash
GET /
GET /health
```

**Response:**
```json
{
  "service": "SMIMSO AI Service",
  "status": "running",
  "device": "cpu",
  "models": {
    "clip": "openai/clip-vit-base-patch32",
    "blip": "Salesforce/blip-image-captioning-base"
  }
}
```

---

### **2. Generate Image Features (CLIP + BLIP)**

```bash
POST /api/ai/image-features
Content-Type: multipart/form-data
```

**Request:**
- `image`: File (JPG, PNG, etc.)

**Response:**
```json
{
  "embedding": [0.123, -0.456, ...],  // 512 dimensions
  "caption": "a beautiful sunset over the ocean"
}
```

**Example (PowerShell):**
```powershell
curl -X POST http://localhost:8000/api/ai/image-features `
  -F "image=@test.jpg"
```

---

### **3. Zero-shot Classification**

```bash
POST /api/ai/classify
Content-Type: multipart/form-data
```

**Request:**
- `image`: File
- `labels`: JSON array of labels

**Response:**
```json
{
  "predictions": [
    {"label": "photo", "score": 0.85},
    {"label": "drawing", "score": 0.10},
    {"label": "painting", "score": 0.05}
  ]
}
```

**Example:**
```powershell
curl -X POST http://localhost:8000/api/ai/classify `
  -F "image=@test.jpg" `
  -F 'labels=["photo","drawing","painting"]'
```

---

### **4. Generate Text Embedding**

```bash
POST /api/ai/text-embedding
Content-Type: application/json
```

**Request:**
```json
{
  "query": "beautiful sunset",
  "limit": 20
}
```

**Response:**
```json
{
  "embedding": [0.123, -0.456, ...],
  "query": "beautiful sunset"
}
```

---

## üîß Configuration

### **Environment Variables:**

T·∫°o file `.env`:

```env
# AI Service Port
PORT=8000

# Device (cpu or cuda)
DEVICE=cpu

# Model Cache Directory (optional)
TRANSFORMERS_CACHE=/path/to/cache
```

---

## üìä Models

### **CLIP (OpenAI)**
- Model: `openai/clip-vit-base-patch32`
- Embedding Dimension: **512**
- Use: Image & Text embeddings

### **BLIP (Salesforce)**
- Model: `Salesforce/blip-image-captioning-base`
- Use: Image captioning

---

## üß™ Testing

### **Test v·ªõi cURL:**

```bash
# Health check
curl http://localhost:8000/health

# Upload image
curl -X POST http://localhost:8000/api/ai/image-features \
  -F "image=@test.jpg"
```

### **Test v·ªõi Python:**

```python
import requests

# Upload image
with open('test.jpg', 'rb') as f:
    response = requests.post(
        'http://localhost:8000/api/ai/image-features',
        files={'image': f}
    )
    print(response.json())
```

---

## ‚ö° Performance

### **First Request:**
- Slow (~10-30s) - Models loading
- CLIP: ~400MB
- BLIP: ~1GB

### **Subsequent Requests:**
- Fast (~1-3s per image)
- CPU: 2-5s
- GPU: 0.5-1s

### **Memory Usage:**
- CPU: ~2-3GB RAM
- GPU: ~2-3GB VRAM

---

## üêõ Troubleshooting

### **Error: "No module named 'torch'"**
```bash
pip install torch torchvision
```

### **Error: "CUDA out of memory"**
- Gi·∫£m batch size
- Ho·∫∑c d√πng CPU: `device = "cpu"`

### **Models download ch·∫≠m:**
- Models s·∫Ω t·ª± ƒë·ªông download l·∫ßn ƒë·∫ßu (~1.5GB)
- L∆∞u t·∫°i `~/.cache/huggingface/`

---

## üîó Integration v·ªõi Backend

Backend ƒë√£ t√≠ch h·ª£p s·∫µn AI Service:

1. **Upload ·∫£nh** ‚Üí Backend g·ªçi `/api/ai/image-features`
2. **Nh·∫≠n embedding + caption** ‚Üí L∆∞u v√†o database
3. **Search** ‚Üí D√πng vector similarity trong PostgreSQL

---

## üìù Notes

- Service n√†y l√† **optional** - Backend v·∫´n ch·∫°y ƒë∆∞·ª£c n·∫øu kh√¥ng c√≥ AI Service
- N·∫øu AI Service fail, backend s·∫Ω l∆∞u ·∫£nh m√† kh√¥ng c√≥ embedding
- C√≥ th·ªÉ ch·∫°y AI Service tr√™n server ri√™ng

---

**Happy Coding! üöÄ**

