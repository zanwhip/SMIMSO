# ğŸ¤– HÆ°á»›ng Dáº«n TÃ­ch Há»£p CLIP - SMIMSO

## ğŸ“‹ Tá»•ng Quan

SMIMSO Ä‘Ã£ tÃ­ch há»£p **CLIP (OpenAI)** vÃ  **BLIP (Salesforce)** Ä‘á»ƒ:

- âœ… **Tá»± Ä‘á»™ng táº¡o embedding** khi upload áº£nh (512 chiá»u)
- âœ… **Tá»± Ä‘á»™ng táº¡o caption** cho áº£nh
- âœ… **Zero-shot classification** - PhÃ¢n loáº¡i áº£nh
- âœ… **Text-to-Image Search** - TÃ¬m áº£nh báº±ng text
- âœ… **Image Similarity** - TÃ¬m áº£nh tÆ°Æ¡ng tá»±

---

## ğŸ—ï¸ Kiáº¿n TrÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend   â”‚â”€â”€â”€â”€â”€â–¶â”‚   Backend   â”‚â”€â”€â”€â”€â”€â–¶â”‚ AI Service  â”‚
â”‚  (Next.js)  â”‚      â”‚  (Node.js)  â”‚      â”‚  (Python)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                     â”‚
                            â–¼                     â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  Supabase   â”‚      â”‚    CLIP     â”‚
                     â”‚ (PostgreSQL)â”‚      â”‚    BLIP     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Flow Khi Upload áº¢nh:**

1. User upload áº£nh tá»« Frontend
2. Backend nháº­n áº£nh â†’ LÆ°u vÃ o `/uploads`
3. Backend gá»i AI Service: `POST /api/ai/image-features`
4. AI Service:
   - CLIP táº¡o embedding (512 chiá»u)
   - BLIP táº¡o caption
5. Backend lÆ°u vÃ o database:
   - `posts` table: post info
   - `post_images` table: image_url, **embedding**, **caption**
6. Tráº£ vá» káº¿t quáº£ cho Frontend

---

## ğŸš€ CÃ i Äáº·t AI Service

### **BÆ°á»›c 1: CÃ i Äáº·t Python Dependencies**

```powershell
cd AI_SERVICE

# Táº¡o virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# CÃ i packages
pip install -r requirements.txt
```

**LÆ°u Ã½:**
- Cáº§n Python 3.8+
- Download models láº§n Ä‘áº§u: ~1.5GB
- Cáº§n ~3GB RAM

### **BÆ°á»›c 2: Cháº¡y AI Service**

```powershell
python main.py
```

hoáº·c

```powershell
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

**Káº¿t quáº£:**
```
INFO:     Loading models on device: cpu
INFO:     Loading CLIP model...
INFO:     âœ… CLIP model loaded successfully
INFO:     Loading BLIP model...
INFO:     âœ… BLIP model loaded successfully
INFO:     ğŸ‰ All models loaded successfully!
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### **BÆ°á»›c 3: Test AI Service**

```powershell
# Test health
curl http://localhost:8000/health

# Test vá»›i script
python test_ai.py
```

---

## ğŸ”§ Cáº¥u HÃ¬nh Backend

### **File: `BACKEND/.env`**

ThÃªm dÃ²ng nÃ y:

```env
AI_SERVICE_URL=http://localhost:8000
```

**LÆ°u Ã½:**
- Náº¿u khÃ´ng cháº¡y AI Service, Ä‘á»ƒ trá»‘ng hoáº·c comment
- Backend váº«n hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng, chá»‰ khÃ´ng cÃ³ embedding/caption

---

## ğŸ“¡ API Endpoints

### **1. Generate Image Features**

**Endpoint:** `POST /api/ai/image-features`

**Request:**
```bash
curl -X POST http://localhost:8000/api/ai/image-features \
  -F "image=@test.jpg"
```

**Response:**
```json
{
  "embedding": [0.123, -0.456, ...],  // 512 dimensions
  "caption": "a beautiful sunset over the ocean"
}
```

### **2. Zero-shot Classification**

**Endpoint:** `POST /api/ai/classify`

**Request:**
```bash
curl -X POST http://localhost:8000/api/ai/classify \
  -F "image=@test.jpg" \
  -F 'labels=["photo","drawing","painting"]'
```

**Response:**
```json
{
  "predictions": [
    {"label": "photo", "score": 0.85},
    {"label": "drawing", "score": 0.10},
    {"label": "painting", "score": 0.05}
  ]
}
```

### **3. Text Embedding**

**Endpoint:** `POST /api/ai/text-embedding`

**Request:**
```json
{
  "query": "beautiful sunset",
  "limit": 20
}
```

**Response:**
```json
{
  "embedding": [0.123, -0.456, ...],
  "query": "beautiful sunset"
}
```

---

## ğŸ§ª Test TÃ­ch Há»£p

### **Test 1: Upload áº¢nh Tá»« Frontend**

1. Cháº¡y Backend: `npm run dev` (port 5000)
2. Cháº¡y AI Service: `python main.py` (port 8000)
3. Cháº¡y Frontend: `npm run dev` (port 3000)
4. VÃ o http://localhost:3000/create-post
5. Upload áº£nh â†’ Submit
6. Kiá»ƒm tra database:
   ```sql
   SELECT id, caption, embedding FROM post_images LIMIT 1;
   ```

### **Test 2: Text-to-Image Search**

```powershell
# Táº¡o text embedding
curl -X POST http://localhost:8000/api/ai/text-embedding \
  -H "Content-Type: application/json" \
  -d '{"query": "sunset beach"}'

# DÃ¹ng embedding Ä‘á»ƒ search trong database (pgvector)
# SELECT * FROM post_images 
# ORDER BY embedding <-> '[0.1, 0.2, ...]' 
# LIMIT 10;
```

---

## ğŸ“Š Database Schema

### **Table: `post_images`**

```sql
CREATE TABLE post_images (
  id UUID PRIMARY KEY,
  post_id UUID REFERENCES posts(id),
  image_url TEXT NOT NULL,
  image_path TEXT,
  embedding vector(512),        -- CLIP embedding
  caption TEXT,                 -- BLIP caption
  display_order INTEGER,
  created_at TIMESTAMP
);

-- Index for vector similarity search
CREATE INDEX idx_post_images_embedding 
ON post_images 
USING ivfflat (embedding vector_cosine_ops);
```

---

## ğŸ” Vector Similarity Search

### **TÃ¬m áº¢nh TÆ°Æ¡ng Tá»±:**

```sql
-- TÃ¬m 10 áº£nh giá»‘ng nháº¥t vá»›i áº£nh cÃ³ id = 'xxx'
SELECT 
  pi2.id,
  pi2.image_url,
  pi2.caption,
  1 - (pi1.embedding <=> pi2.embedding) as similarity
FROM post_images pi1
CROSS JOIN post_images pi2
WHERE pi1.id = 'xxx' AND pi2.id != 'xxx'
ORDER BY pi1.embedding <=> pi2.embedding
LIMIT 10;
```

### **TÃ¬m áº¢nh Báº±ng Text:**

```sql
-- 1. Táº¡o text embedding tá»« AI Service
-- 2. Search trong database
SELECT 
  id,
  image_url,
  caption,
  1 - (embedding <=> '[0.1, 0.2, ...]') as similarity
FROM post_images
ORDER BY embedding <=> '[0.1, 0.2, ...]'
LIMIT 10;
```

---

## âš¡ Performance

### **Láº§n Äáº§u (Cold Start):**
- Load models: 10-30s
- CLIP: ~400MB
- BLIP: ~1GB

### **Sau ÄÃ³:**
- CPU: 2-5s per image
- GPU: 0.5-1s per image

### **Memory:**
- CPU: ~2-3GB RAM
- GPU: ~2-3GB VRAM

---

## ğŸ› Troubleshooting

### **1. AI Service khÃ´ng cháº¡y Ä‘Æ°á»£c:**

```
Error: No module named 'torch'
```

**Fix:**
```bash
pip install torch torchvision
```

### **2. Backend khÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c AI Service:**

```
AI service error: connect ECONNREFUSED
```

**Fix:**
- Kiá»ƒm tra AI Service Ä‘ang cháº¡y: `curl http://localhost:8000/health`
- Kiá»ƒm tra `AI_SERVICE_URL` trong `.env`

### **3. Models download cháº­m:**

**Fix:**
- Models tá»± Ä‘á»™ng download láº§n Ä‘áº§u (~1.5GB)
- LÆ°u táº¡i `~/.cache/huggingface/`
- CÃ³ thá»ƒ download trÆ°á»›c:
  ```python
  from transformers import CLIPModel, BlipForConditionalGeneration
  CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
  BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
  ```

---

## ğŸ“ Notes

### **AI Service lÃ  Optional:**

- Backend váº«n cháº¡y Ä‘Æ°á»£c náº¿u khÃ´ng cÃ³ AI Service
- Náº¿u AI Service fail, áº£nh váº«n Ä‘Æ°á»£c lÆ°u, chá»‰ khÃ´ng cÃ³ embedding/caption
- CÃ³ thá»ƒ báº­t/táº¯t AI features báº±ng cÃ¡ch comment `AI_SERVICE_URL`

### **Production Deployment:**

- NÃªn cháº¡y AI Service trÃªn server riÃªng (cÃ³ GPU)
- DÃ¹ng Docker Ä‘á»ƒ deploy
- Cache embeddings Ä‘á»ƒ trÃ¡nh tÃ­nh láº¡i

---

## ğŸ¯ TÃ³m Táº¯t

âœ… **AI Service**: Python FastAPI + CLIP + BLIP  
âœ… **Backend**: Tá»± Ä‘á»™ng gá»i AI Service khi upload  
âœ… **Database**: LÆ°u embedding (512D) + caption  
âœ… **Search**: Vector similarity vá»›i pgvector  
âœ… **Optional**: Backend váº«n cháº¡y náº¿u khÃ´ng cÃ³ AI  

---

**Happy Coding! ğŸš€**

